{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Netwoek Notebook\n",
    "\n",
    "In this notebook, read the data and clean it, then normalize it and use it as the input of neural nework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data and do the pre-processing and preparing data for classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import umap\n",
    "import imblearn\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_FOR</th>\n",
       "      <th>RTD_ST_CD</th>\n",
       "      <th>CustomerSegment</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Age</th>\n",
       "      <th>MART_STATUS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>CHANNEL1_6M</th>\n",
       "      <th>CHANNEL2_6M</th>\n",
       "      <th>CHANNEL3_6M</th>\n",
       "      <th>...</th>\n",
       "      <th>CHANNEL5_3M</th>\n",
       "      <th>METHOD1_3M</th>\n",
       "      <th>PAYMENTS_3M</th>\n",
       "      <th>NOT_DI_3M</th>\n",
       "      <th>NOT_DI_6M</th>\n",
       "      <th>EVENT1_30_FLAG</th>\n",
       "      <th>EVENT2_90_SUM</th>\n",
       "      <th>LOGINS</th>\n",
       "      <th>POLICYPURCHASECHANNEL</th>\n",
       "      <th>Call_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/19/2014</td>\n",
       "      <td>ST_S0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.175222</td>\n",
       "      <td>78.403833</td>\n",
       "      <td>MS_S0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/17/2014</td>\n",
       "      <td>ST_S0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.931554</td>\n",
       "      <td>70.989733</td>\n",
       "      <td>MS_S1</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/15/2014</td>\n",
       "      <td>ST_S0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.937029</td>\n",
       "      <td>87.578371</td>\n",
       "      <td>MS_S2</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/16/2014</td>\n",
       "      <td>ST_S1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.934292</td>\n",
       "      <td>68.438056</td>\n",
       "      <td>MS_S2</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/20/2014</td>\n",
       "      <td>ST_S0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.501711</td>\n",
       "      <td>80.514716</td>\n",
       "      <td>MS_S0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DATE_FOR RTD_ST_CD CustomerSegment     Tenure        Age MART_STATUS  \\\n",
       "0  5/19/2014     ST_S0               1  16.175222  78.403833       MS_S0   \n",
       "1  5/17/2014     ST_S0               1  15.931554  70.989733       MS_S1   \n",
       "2  5/15/2014     ST_S0               1  15.937029  87.578371       MS_S2   \n",
       "3  5/16/2014     ST_S1               1  15.934292  68.438056       MS_S2   \n",
       "4  5/20/2014     ST_S0               1  15.501711  80.514716       MS_S0   \n",
       "\n",
       "  GENDER  CHANNEL1_6M  CHANNEL2_6M  CHANNEL3_6M  ...  CHANNEL5_3M  METHOD1_3M  \\\n",
       "0      F          0.0          0.0          1.0  ...            2           0   \n",
       "1      F          0.0          6.0          0.0  ...            0           3   \n",
       "2      M          0.0          0.0         10.0  ...            0           0   \n",
       "3      M          0.0          0.0          1.0  ...            0           0   \n",
       "4      F          0.0          0.0          1.0  ...            0           0   \n",
       "\n",
       "   PAYMENTS_3M  NOT_DI_3M  NOT_DI_6M  EVENT1_30_FLAG  EVENT2_90_SUM  LOGINS  \\\n",
       "0            3          0          0               0              0       0   \n",
       "1            3          0          0               0              0       0   \n",
       "2            6          0          0               0              0       0   \n",
       "3            0          0          0               0              0       0   \n",
       "4            1          0          0               0              0       0   \n",
       "\n",
       "   POLICYPURCHASECHANNEL  Call_Flag  \n",
       "0                      0          0  \n",
       "1                      0          0  \n",
       "2                      0          0  \n",
       "3                      1          0  \n",
       "4                      0          0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('DS_MiniProject_ANON-Copy1.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processin the data\n",
    "### Find the Shape and Missing values of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: \n",
      " ['DATE_FOR' 'RTD_ST_CD' 'CustomerSegment' 'Tenure' 'Age' 'MART_STATUS'\n",
      " 'GENDER' 'CHANNEL1_6M' 'CHANNEL2_6M' 'CHANNEL3_6M' 'CHANNEL4_6M'\n",
      " 'CHANNEL5_6M' 'METHOD1_6M' 'RECENT_PAYMENT' 'PAYMENTS_6M' 'CHANNEL1_3M'\n",
      " 'CHANNEL2_3M' 'CHANNEL3_3M' 'CHANNEL4_3M' 'CHANNEL5_3M' 'METHOD1_3M'\n",
      " 'PAYMENTS_3M' 'NOT_DI_3M' 'NOT_DI_6M' 'EVENT1_30_FLAG' 'EVENT2_90_SUM'\n",
      " 'LOGINS' 'POLICYPURCHASECHANNEL' 'Call_Flag']\n",
      "data_shape: (130086, 29)\n",
      "Missing values: DATE_FOR                   0\n",
      "RTD_ST_CD                  0\n",
      "CustomerSegment            0\n",
      "Tenure                     0\n",
      "Age                        0\n",
      "MART_STATUS                0\n",
      "GENDER                     0\n",
      "CHANNEL1_6M              809\n",
      "CHANNEL2_6M              809\n",
      "CHANNEL3_6M              809\n",
      "CHANNEL4_6M              809\n",
      "CHANNEL5_6M              809\n",
      "METHOD1_6M               809\n",
      "RECENT_PAYMENT           809\n",
      "PAYMENTS_6M              809\n",
      "CHANNEL1_3M                0\n",
      "CHANNEL2_3M                0\n",
      "CHANNEL3_3M                0\n",
      "CHANNEL4_3M                0\n",
      "CHANNEL5_3M                0\n",
      "METHOD1_3M                 0\n",
      "PAYMENTS_3M                0\n",
      "NOT_DI_3M                  0\n",
      "NOT_DI_6M                  0\n",
      "EVENT1_30_FLAG             0\n",
      "EVENT2_90_SUM              0\n",
      "LOGINS                     0\n",
      "POLICYPURCHASECHANNEL      0\n",
      "Call_Flag                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features_list = data.columns.values\n",
    "print('Features: \\n', features_list)\n",
    "print('data_shape:', data.shape)\n",
    "print('Missing values:', data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_data_shape: (129277, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Age</th>\n",
       "      <th>CHANNEL1_6M</th>\n",
       "      <th>CHANNEL2_6M</th>\n",
       "      <th>CHANNEL3_6M</th>\n",
       "      <th>CHANNEL4_6M</th>\n",
       "      <th>CHANNEL5_6M</th>\n",
       "      <th>METHOD1_6M</th>\n",
       "      <th>RECENT_PAYMENT</th>\n",
       "      <th>PAYMENTS_6M</th>\n",
       "      <th>...</th>\n",
       "      <th>CHANNEL5_3M</th>\n",
       "      <th>METHOD1_3M</th>\n",
       "      <th>PAYMENTS_3M</th>\n",
       "      <th>NOT_DI_3M</th>\n",
       "      <th>NOT_DI_6M</th>\n",
       "      <th>EVENT1_30_FLAG</th>\n",
       "      <th>EVENT2_90_SUM</th>\n",
       "      <th>LOGINS</th>\n",
       "      <th>POLICYPURCHASECHANNEL</th>\n",
       "      <th>Call_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.0</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "      <td>129277.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.591581</td>\n",
       "      <td>48.813929</td>\n",
       "      <td>0.261810</td>\n",
       "      <td>0.948467</td>\n",
       "      <td>0.811652</td>\n",
       "      <td>0.401216</td>\n",
       "      <td>0.569823</td>\n",
       "      <td>1.834425</td>\n",
       "      <td>0.105680</td>\n",
       "      <td>4.848333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285333</td>\n",
       "      <td>0.914494</td>\n",
       "      <td>2.427145</td>\n",
       "      <td>0.056019</td>\n",
       "      <td>0.080502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193522</td>\n",
       "      <td>0.953774</td>\n",
       "      <td>0.131284</td>\n",
       "      <td>0.036549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.297798</td>\n",
       "      <td>14.037131</td>\n",
       "      <td>1.092346</td>\n",
       "      <td>1.880123</td>\n",
       "      <td>1.824188</td>\n",
       "      <td>1.065413</td>\n",
       "      <td>1.628655</td>\n",
       "      <td>2.596754</td>\n",
       "      <td>0.307429</td>\n",
       "      <td>2.027548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850155</td>\n",
       "      <td>1.388627</td>\n",
       "      <td>1.211655</td>\n",
       "      <td>0.229960</td>\n",
       "      <td>0.272069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509437</td>\n",
       "      <td>2.149006</td>\n",
       "      <td>0.337712</td>\n",
       "      <td>0.187654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.032854</td>\n",
       "      <td>16.689938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.252567</td>\n",
       "      <td>37.845311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.006160</td>\n",
       "      <td>49.111567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.630390</td>\n",
       "      <td>58.830938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.091034</td>\n",
       "      <td>99.348392</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tenure            Age    CHANNEL1_6M    CHANNEL2_6M  \\\n",
       "count  129277.000000  129277.000000  129277.000000  129277.000000   \n",
       "mean        8.591581      48.813929       0.261810       0.948467   \n",
       "std         7.297798      14.037131       1.092346       1.880123   \n",
       "min         0.032854      16.689938       0.000000       0.000000   \n",
       "25%         3.252567      37.845311       0.000000       0.000000   \n",
       "50%         7.006160      49.111567       0.000000       0.000000   \n",
       "75%        11.630390      58.830938       0.000000       1.000000   \n",
       "max        63.091034      99.348392      12.000000      53.000000   \n",
       "\n",
       "         CHANNEL3_6M    CHANNEL4_6M    CHANNEL5_6M     METHOD1_6M  \\\n",
       "count  129277.000000  129277.000000  129277.000000  129277.000000   \n",
       "mean        0.811652       0.401216       0.569823       1.834425   \n",
       "std         1.824188       1.065413       1.628655       2.596754   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       4.000000   \n",
       "max        26.000000      18.000000      29.000000      53.000000   \n",
       "\n",
       "       RECENT_PAYMENT    PAYMENTS_6M  ...    CHANNEL5_3M     METHOD1_3M  \\\n",
       "count   129277.000000  129277.000000  ...  129277.000000  129277.000000   \n",
       "mean         0.105680       4.848333  ...       0.285333       0.914494   \n",
       "std          0.307429       2.027548  ...       0.850155       1.388627   \n",
       "min          0.000000       1.000000  ...       0.000000       0.000000   \n",
       "25%          0.000000       4.000000  ...       0.000000       0.000000   \n",
       "50%          0.000000       6.000000  ...       0.000000       0.000000   \n",
       "75%          0.000000       6.000000  ...       0.000000       2.000000   \n",
       "max          1.000000      53.000000  ...      16.000000      36.000000   \n",
       "\n",
       "         PAYMENTS_3M      NOT_DI_3M      NOT_DI_6M  EVENT1_30_FLAG  \\\n",
       "count  129277.000000  129277.000000  129277.000000        129277.0   \n",
       "mean        2.427145       0.056019       0.080502             0.0   \n",
       "std         1.211655       0.229960       0.272069             0.0   \n",
       "min         0.000000       0.000000       0.000000             0.0   \n",
       "25%         2.000000       0.000000       0.000000             0.0   \n",
       "50%         3.000000       0.000000       0.000000             0.0   \n",
       "75%         3.000000       0.000000       0.000000             0.0   \n",
       "max        36.000000       1.000000       1.000000             0.0   \n",
       "\n",
       "       EVENT2_90_SUM         LOGINS  POLICYPURCHASECHANNEL      Call_Flag  \n",
       "count  129277.000000  129277.000000          129277.000000  129277.000000  \n",
       "mean        0.193522       0.953774               0.131284       0.036549  \n",
       "std         0.509437       2.149006               0.337712       0.187654  \n",
       "min         0.000000       0.000000               0.000000       0.000000  \n",
       "25%         0.000000       0.000000               0.000000       0.000000  \n",
       "50%         0.000000       0.000000               0.000000       0.000000  \n",
       "75%         0.000000       1.000000               0.000000       0.000000  \n",
       "max         4.000000      45.000000               1.000000       1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "print('clean_data_shape:', data.shape)\n",
    "data.drop(['DATE_FOR'], axis=1, inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the percentage of calls\n",
    "Take a look at the distribution of the calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset: 130086\n",
      "All calls: 4764\n",
      "Not_call: 125322\n",
      "Percentage of Calls: 0.036621927032885936\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = data['Call_Flag'].value_counts()\n",
    "calls = counts[1]\n",
    "non_calls = counts[0]\n",
    "print('length of dataset:', len(data))\n",
    "print('All calls:',calls )\n",
    "print('Not_call:',non_calls )\n",
    "print('Percentage of Calls:', calls/(non_calls+calls))\n",
    "\n",
    "fig = plt.figure(figsize = (6, 4))  \n",
    "# creating the bar plot \n",
    "plt.bar([0,1], data['Call_Flag'].value_counts(), color ='maroon',  \n",
    "        width = 0.5)   \n",
    "plt.xlabel(\"Calls or no calls\") \n",
    "plt.ylabel(\"Frequency\") \n",
    "plt.title(\"How many calls recieved\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization \n",
    "Visualization of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hist_list = ['Tenure', 'Age','LOGINS' ]\n",
    "n_bins = 50 \n",
    "\n",
    "for column_name in Hist_list:\n",
    "    ax=plt.subplots(figsize=(6,3))\n",
    "    # get data by column_name and display a histogram\n",
    "    ax = plt.hist(data[column_name], bins=n_bins)\n",
    "    title=\"Histogram of \" + column_name\n",
    "    plt.title(title, fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15edda99898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAADuCAYAAAB4buV5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3df7QkZXng8e/DAKKgARQPODCCOoqYqOAs4mbjL3TlhzrRJAouovhjJAGzmqiLns1Rj4lLjCaKIpMRUVFXjiGumSzoKKhEV0EGRHBEzIgoA2McDeIPjIg8+0fVSNPeO/ftW3VvV9X9fs7pc7ur6n3red9+q7qfW9VVkZlIkiRJkrpvp2kHIEmSJEkqYwInSZIkST1hAidJkiRJPWECJ0mSJEk9YQInSZIkST1hAidJkiRJPVGUwEXEURFxXURsjojTZph/cER8KSJ+ERGvmqSsJEmSJKlMzHUfuIhYBnwTeCqwBbgcOD4zvz6yzP2BBwK/D9ySmW8tLStJkiRJKlNyBO5wYHNmXp+ZtwPnAatHF8jM72fm5cAvJy0rSZIkSSqzc8Eyy4EbR15vAR5bWH9x2YhYA6wB2H333R9z8MEHF65CkiRJkobliiuu+EFm7jM+vSSBixmm7fi8y3mUzcx1wDqAVatW5caNGwtXIUmSJEnDEhHfmWl6ySmUW4ADRl7vD9xcuN4mZSVJkiRJI0oSuMuBlRFxUETsChwHrC+sv0lZSZIkSdKIOU+hzMw7IuJUYAOwDDgnMzdFxMn1/LURsS+wEbgPcGdEvAI4JDN/PFPZhWqMJEmSJA3ZnLcRmAZ/AydJkiRpKYuIKzJz1fj0oht5S5IkSZKmr+QqlJIkSZKkeTrwtAt2OP+G048trssjcJIkSZLUEyZwkiRJktQTJnCSJEmS1BMmcJIkSZLUEyZwkiRJktQTJnCSJEmS1BMmcJIkSZLUEyZwkiRJktQTJnCSJEmS1BMmcJIkSZLUEyZwkiRJktQTJnCSJEmS1BMmcJIkSZLUEyZwkiRJktQTJnCSJEmS1BMmcJIkSZLUEyZwkiRJktQTJnCSJEmS1BMmcJIkSZLUEyZwkiRJktQTJnCSJEmS1BMmcJIkSZLUE0UJXEQcFRHXRcTmiDhthvkREWfU86+OiMNG5r0yIjZFxNci4iMRsVubDZAkSZKkpWLOBC4ilgFnAkcDhwDHR8QhY4sdDaysH2uAs+qyy4E/BVZl5m8Dy4DjWotekiRJkpaQkiNwhwObM/P6zLwdOA9YPbbMauDcrFwK7BkR+9XzdgbuGRE7A/cCbm4pdkmSJElaUkoSuOXAjSOvt9TT5lwmM28C3gp8F9gK3JqZn5ppJRGxJiI2RsTGbdu2lcYvSZIkSUtGSQIXM0zLkmUiYi+qo3MHAQ8Ado+IE2ZaSWauy8xVmblqn332KQhLkiRJkpaWkgRuC3DAyOv9+c3TIGdb5inAtzNzW2b+EvgY8J/nH64kSZIkLV0lCdzlwMqIOCgidqW6CMn6sWXWAyfWV6M8gupUya1Up04eERH3iogAjgSubTF+SZIkSVoydp5rgcy8IyJOBTZQXUXynMzcFBEn1/PXAhcCxwCbgduAk+p5l0XE+cCVwB3AV4B1C9EQSZIkSRq6ORM4gMy8kCpJG522duR5AqfMUvb1wOsbxChJkiRJovBG3pIkSZKk6TOBkyRJkqSeMIGTJEmSpJ4wgZMkSZKknjCBkyRJkqSeKLoKpSRJkiQtVQeedsEO599w+rGLFIlH4CRJkiSpN0zgJEmSJKknTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKknTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKknTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKknTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKknTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKknihK4iDgqIq6LiM0RcdoM8yMizqjnXx0Rh43M2zMizo+Ib0TEtRHxuDYbIEmSJElLxZwJXEQsA84EjgYOAY6PiEPGFjsaWFk/1gBnjcx7B/DJzDwYeBRwbQtxS5IkSdKSU3IE7nBgc2Zen5m3A+cBq8eWWQ2cm5VLgT0jYr+IuA/weOC9AJl5e2b+qMX4JUmSJGnJKEnglgM3jrzeUk8rWeZBwDbgfRHxlYg4OyJ2n2klEbEmIjZGxMZt27YVN0CSJEmSloqdC5aJGaZl4TI7A4cBL8/MyyLiHcBpwF/8xsKZ64B1AKtWrRqvX5IkSZImduBpF8y5zA2nH7sIkbSj5AjcFuCAkdf7AzcXLrMF2JKZl9XTz6dK6CRJkiRJEypJ4C4HVkbEQRGxK3AcsH5smfXAifXVKI8Abs3MrZn5PeDGiHhYvdyRwNfbCl6SJEmSlpI5T6HMzDsi4lRgA7AMOCczN0XEyfX8tcCFwDHAZuA24KSRKl4OfLhO/q4fmydJkiRJKlTyGzgy80KqJG102tqR5wmcMkvZq4BVDWKUJEmSJFF4I29JkiRJ0vQVHYGTJEmSpGmY6yqSfbqCZBs8AidJkiRJPWECJ0mSJEk9YQInSZIkST1hAidJkiRJPWECJ0mSJEk9YQInSZIkST1hAidJkiRJPWECJ0mSJEk9YQInSZIkST1hAidJkiRJPWECJ0mSJEk9YQInSZIkST2x87QDkCRJkjRcB552wQ7n33D6sYsUyTCYwEmSJEmakclX93gKpSRJkiT1hAmcJEmSJPWEp1BKkiRJHTTX6Ysw9ymMngI5PCZwkiRJ0gIwedJC8BRKSZIkSeoJEzhJkiRJ6glPoZQkSdLgtHH6oqdAqos8AidJkiRJPVF0BC4ijgLeASwDzs7M08fmRz3/GOA24IWZeeXI/GXARuCmzHx6S7FLkiRpATQ98uTVE6WFM+cRuDr5OhM4GjgEOD4iDhlb7GhgZf1YA5w1Nv+/A9c2jlaSJEmSlrCSUygPBzZn5vWZeTtwHrB6bJnVwLlZuRTYMyL2A4iI/YFjgbNbjFuSJEmSlpySUyiXAzeOvN4CPLZgmeXAVuDtwGuAe+9oJRGxhuroHStWrCgIS5IkSTPx9ENpuEoSuJhhWpYsExFPB76fmVdExBN3tJLMXAesA1i1atV4/ZIkSUuCyZekHSk5hXILcMDI6/2BmwuX+V3gmRFxA9Wpl0+OiA/NO1pJkiRJWsJKjsBdDqyMiIOAm4DjgOeNLbMeODUizqM6vfLWzNwKvLZ+UB+Be1VmntBS7JIkaUC6cOVC7x0mqevmTOAy846IOBXYQHUbgXMyc1NEnFzPXwtcSHULgc1UtxE4aeFCliRJXWTiIkkLr+g+cJl5IVWSNjpt7cjzBE6Zo47PAZ+bOEJJkiRJElCYwEmSpG7z1D9JWhpM4CRJ6gCTJ0lSCRM4SdKSt9AXviipQ5KkEiZwkqTe8+iVJGmpMIGTJE2VyZckSeVM4CRpiqZ9z6ou3HdLkiSVM4GT1EtduOKeiYskSVpsO007AEmSJElSGRM4SZIkSeoJEzhJkiRJ6gkTOEmSJEnqCRM4SZIkSeoJEzhJkiRJ6glvIyBpKrwEvyRJ0uRM4CRNrI2bP0uSJGlyJnDSIvMG1JIkSZovEzhpQiY/kiRJmhYTOC0pnvonSZKkPjOBU6949EuSJElLmbcRkCRJkqSeMIGTJEmSpJ4wgZMkSZKknvA3cCrWhcvfS5IkSUtZUQIXEUcB7wCWAWdn5ulj86OefwxwG/DCzLwyIg4AzgX2Be4E1mXmO1qMf8lo4+qJJk+SJElSv82ZwEXEMuBM4KnAFuDyiFifmV8fWexoYGX9eCxwVv33DuDP62Tu3sAVEfHpsbJLgsmTJEmSpKZKfgN3OLA5M6/PzNuB84DVY8usBs7NyqXAnhGxX2ZuzcwrATLzJ8C1wPIW45ckSZKkJaPkFMrlwI0jr7dQHV2ba5nlwNbtEyLiQOBQ4LKZVhIRa4A1ACtWrCgIa3F5BE2SJEnStJUcgYsZpuUky0TEHsA/Aq/IzB/PtJLMXJeZqzJz1T777FMQliRJkiQtLSUJ3BbggJHX+wM3ly4TEbtQJW8fzsyPzT9USZIkSVraSk6hvBxYGREHATcBxwHPG1tmPXBqRJxHdXrlrZm5tb465XuBazPzb1uMeyKe/ihJkiRpCOZM4DLzjog4FdhAdRuBczJzU0ScXM9fC1xIdQuBzVS3ETipLv67wPOBayLiqnra6zLzwnabIUmSJEnDV3QfuDrhunBs2tqR5wmcMkO5LzDz7+MkSZIkSRMq+Q2cJEmSJKkDTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKknTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKkniu4DN20HnnbBDuffcPqxixSJJEmSJE2PR+AkSZIkqSdM4CRJkiSpJ0zgJEmSJKknTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKknTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKknTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKknTOAkSZIkqSdM4CRJkiSpJ0zgJEmSJKknihK4iDgqIq6LiM0RcdoM8yMizqjnXx0Rh5WWlSRJkiSVmTOBi4hlwJnA0cAhwPERccjYYkcDK+vHGuCsCcpKkiRJkgqUHIE7HNicmddn5u3AecDqsWVWA+dm5VJgz4jYr7CsJEmSJKlASQK3HLhx5PWWelrJMiVlJUmSJEkFIjN3vEDEHwFPy8yX1K+fDxyemS8fWeYC4H9l5hfq1xcDrwEeNFfZkTrWUJ1+CfAw4LodhHU/4AdFLVyY8l2IYQht6EIMQ2iDMbRT3hjaKW8M7ZQ3hu7EMIQ2dCGGIbShCzEMoQ3GUF7+gZm5z29MzcwdPoDHARtGXr8WeO3YMn8PHD/y+jpgv5Ky83kAG6dZvgsxDKENXYhhCG0whuG0oQsxDKENXYhhCG0whuG0oQsxDKENXYhhCG0whublS06hvBxYGREHRcSuwHHA+rFl1gMn1lejPAK4NTO3FpaVJEmSJBXYea4FMvOOiDgV2AAsA87JzE0RcXI9fy1wIXAMsBm4DThpR2UXpCWSJEmSNHBzJnAAmXkhVZI2Om3tyPMETikt24J1Uy7fhRiG0IYuxDCENhhDO+WNoZ3yxtBOeWPoTgxDaEMXYhhCG7oQwxDaYAwNy895ERNJkiRJUjeU/AZOkiRJktQBJnCSJEmS1BMmcJIkSZLUEyZwkqTWRMR9IuIxEbHXPMruFRH3Xoi4NJmI2Hs+76FmFhGHTTsGSXcXEfebdgzz1bsErr6n3LMj4uAJyuwREX8YEa+MiJdHxFER0ajtEfHmCZffNyL2rZ/vU7fhERPW8VsR8dyI+LO6Lc+NiD0nqWOkrvn0Y+P1N+2Hpu9lRKyIiN3q5xERJ0XEOyPijyNizquyNi3fRhvqOh4fEQ+rn/+XiHhVRBw7SR2z1PvUCZZtNB7qL/oPnmH6IwvLT70fm7ZhhnITb5cz1DHpvumZ28f0PNf3oe0fghHxNGAT8NfAVRHxRwXlHxAR50bErcAPgE0R8d2IeENE7DLfuEbqLxrTLeybmvbjwRHxiYi4ICIeHBHvj4gfRcSXI+Lh86xz0rGwIiLOi4htwGXA5RHx/XragQXlG/VBG3VExAF1vJ+PiNeNjqGI+Pg865y0Hw8bezwGWB8Rh0ZhItfC/rHpZ92/R8TZEXFkRETJOtuOoS7X+LvTSF2N969j9ZXuW9r47tSpz6qR8sXfGXZQxzUFy7xo5Pn+EXFxvX/8YkQ8tHA9R0fEtyPiC/W2uAm4LCK2RMSRhXU0/d7T3ne3pncxX+gH8PGR56uBbwPvA64DXlhQ/jlUNxQ/G/gW8EHgw8DVwO8UxnDG2OOdwI+2vy4o/7I67huAP6b6YDynbsOLC2M4sY7/LOB/1o+19bQTF6EfG62/jX5o6b38GnCv+vlfA+cDJ9RxnLMI5dtow9uBLwJfBt5UP/8L4CLgbxpub99dpPH4HOBm4CqqL/z/aWTelX3ox6ZtqJdrul022jfVdfycKnH6INX9PJdNOGauGXn+ReDA+vn9gK8WlP8M8MT6+bOBvwN2B/4SWNdkPJeOadrZRzftx38BngEcD3wHOA6IetrFizQWvgQ8dzR2qnu4HgdcutB90FI/fho4GXh03QdfBO5bz/vKIvXjnfV6Pzvy+Hn99zMF5dvYtzT9rLoOOBX4f8BNwDuAIyZ8L5rG0PQ7Q6P9a0H9JfuWNr47Tf2zqkkf1Ms9e5bHHwDbCspfOfL8o/XY2Al4FgX7x7rcVcDDgccBP9w+nutpJd87mn7vafW7W6PBuxgPRna4dWMPqp+Xfjm4emQHcj9gQ/38kcAXC2PYAnyofvNeUD+2bX9eUP4a4F7AfYGfAvvW0/cCriqM4Tpgzxmm7wV8cxH6sdH62+iHlt7Lr488vwLYaeR1ST80Ld9GGzZRfbG7F3DLSH27AF8rKL9+lsc/Az9bpPF4FbBf/fxw4BvAs8fHasf7sVEbxpeb53bZaN+0PYb6fXspcDHwb1QfSk+YoB/vUz//wtg2samg/FfHXl8x8vwbhTE0GtO0s49u2o+jY2Hz2LySLxdtjIV/nc+8tvqgpX68auz1CfUYffAi9uMfApcAx4xM+/YEfdDGvqXpZ9XoF+YVwGuAK4HrgTcvUgxNvzM02r/Wyzbdt7Tx3Wmqn1VN+6Cu45fA+6kS6PHHTyYcj+PbeOk2MVrHjeN9tNDvZdP3cfxRdAh7ynLk+c6Z+W2AzPxBRNxZUD6o/vMF8DPg/nX5qyPiPoUxPJwqWz4KeHVm3hQRr8/MDxSW/2Vm3gbcFhHfyszv1THcEhE5R9nRdsy07J31vLm00Y9N1g/N+6GN9/LGiHhyZn6G6r96BwDfiYj7LlL5NtqQmZkj79v2vruTstOif4/qS81PZ4jt8MIYmo6HZZm5FSAzvxwRTwL+b0TsP0u9M61/2v3YtA2j64T5bZdN90316vIW4D3Ae+rTlZ4DnB4R+2fmAXOUfyPw2Yg4k+q/9f8QEf8EPBn4ZMH6t0XECVRH4v6AaruiPm2r9JTYpmO6jX10035cNvL8b8fm7Vqw/jbGwhUR8W7gA8CN9bQDqJKXrxSUb9oHbdSxS0Tslpn/UVf2oYj4HrCB6sjuXBr3Y2aeHxGfBN4UEScBf075PgHa2be08VlFHcN3gbcAb6lP/zpukWJoul023b9C831LG9+dpv1Z1cZ3hquBt2bm18ZnRMRTCsrvHxFn1OvcJyJ2ycxf1vNKT7X/UUS8DLgPcEtEvJLqaN5T+M22zaTx9/CG7+Pd9CGBe1RE/Jiqc+4REftm5vciYlfu/oE3mwuBT0bEJcDRwD9A9QNtCjeezPwJ8IqozmP/UERcwGSdfefIYPv1ua5RnRteWs9fAVdGxKe464N1BfBUqg+buTTtx6brh+b90Pi9BF4CnBsRbwBupfqdzvb/+P7ZIpRvow0XRMTngd2oTiH8aERcCjyB6jSsuVwK3JaZl4zPiIjrCmNoOh5+EhEPzsxvAWTm1oh4IvBxoOT3DV3ox5na8CTg/xS2ARpuly3sm2Csv+ovSWcAZ0TEAwti+GhEXEl1xOShVJ8rjwM+kpkbCtb/IuCtwGlU/yk+tZ6+N/DawjY0HdNt7KMb9SNwZkTskZk/zcx3j8TwEKpTbHaopbFwIvBiqqR8OVWbtlD9t/29BeWb9kEbdZwNPJbqCNj2Oi6K6veYb5mrcEv9SGb+FHhlRDyaKiGe5OI8TfeP0Pyz6rMzTczM66jGx2LE0HS7bPq9B5rvW9r47rQQn1VPpHw8tfGd4RXAj2eZ96yC8q8eeb4R2IMqCduXav9U4gVUpz3eCfxXqtPVN1Cdsv7SgvJN38um7+PdRH34rnei+tHgwzPzSwXLHgMcQnXI/NP1tJ2AXTLzFxOuN4A/AR6XmScUllkB3JyZd4xNX163Yc4P53r5vYCncfcP1g31fyvnZcJ+bLT+NvqhrfcyqosCbP+yuQW4PDNL/yPXqHwbbYiIx1H9N+fSqH6Y/Czgu8D5k7SjiSbjISIeRXXqxeax6bsAz8nMDxfUMdV+bKMNO6i7eLscKTPxvqku98TM/NzkUQ5HvW/aOvIf3e3TJ9k3daYf5zsWWlhv4z4YYj/W9exRJ4clyz+K6gvzv45Nn3jf0vSzrg3zjaGN7XKWeifevzbRxne3Fj6rWhlPS10L34Pb++6WE55z2YUHcNi0Y/Dhe+mjW48ujKUuxDCFNr8UWFk/D6qLDNxKdcrMnP0xQ/n3Uf2n9mrg0Gm3b4r9uOj90PS9XMC4ite9EP04adu72o8N2zDaj/NuQ1/av8B927gPpt2PLWwTE42nNrbrIWyXd2vPtAMoGSRjj8dQZbyHFr7pBwDnAZ8HXkf13/nt8z5eGMPBwCeAC6h+CP1+qqtSfZnqvzhN2nfNYsRAdV7/tNvQ9L1s/D60MR6a9kMHxkLv+7HpWGqjDR2JYer7N6orze1SP38e1cUK7kv1u4LPL3T5DvVj0xga98MO6i7dt3QhhqafE03H4/j6D5vHdt00ht5v1230ZdM2tDEem9bR0nia6nenputvaZtoYzw2jeFFI8+XU11k6RaqC+Q8dLHHYx9+A7eR6vzb0VOi7kv1I++k+qH8jpwD/GNdx4uBSyLiGZn5Q6D0nPx1wN9QnXP7GeB/ACcBTwfeBezw/hER8ezZZgH7LkYMwN83Kd9SG5q+l037ABqOh6b90JGx0Pt+pPlYgub7hi7EMPX9G3BH3nWK09OBc+v1XxQRc/7mqIXy0I1+bFpHo35oad/ShRiabldNx1Mb23XTGIawXcOUP/PbGI8d+aya9nenLmwTbYzHpnWcSrVtQnW7m49S/f5tNdWtBRbje/RdmmSMi/Gghcvxjr2e6JLCdZmml3dudPnUlmLoQhuavpeN2tDGeGjaD0MYCx3px0ZjqaU2dCGGLuzfrgT2o/ph9r8BjxiZd+1Cl+9QPzaNoWk/trFv6UIMTT8nmrahje26aQy9365bei+78L2lC59V0+7HLmwTbYzHxjGMPJ/4VgZtjMe71TdpgWk8qP5r8HdUV5pbAVw/QdlNwG5j054CbKb6cWxJHVePPP+TsXkl9+C4AvjtWebduEgxTL0NLbyXjdrQxnho2g9DGAtd6MemY6mNNnQhho7s355OdaPf7wHvGZn+BOCChS7foX5sGkPTfmxjm5p6DPWyTT4n2hhPTbfrpv3Y++26pfdy6t9bWqqj0Xiadj+20YYWtok2tuumMXyf6oq476zrGT21edG+R/+6zKQFpvkAHk11ads579o+UuaVzHADUKpzdz9dWMfLqK4gNT79IcDbC8r/HrBilnmrFimGqbehhfeyURvaGA9N+2EIY6EL/dh0LLXRhi7E0IX9W73szsBeY9N2H60XeOoClu9CP7ZRx7z7oa1tqgsxjJSZ73bVaDw1XX8L/TiI7bppXzZtQxvjsc0x3WQ8TbMf22pD0/HUxnhsuF2+YOyxVz19Xwpubt/2/rF3txGY9HK86i7fS7WlC2OpCzF0WURcmZmHTav8UHShHxYzhoXarkrbsJDbdRfey6YmaYP7yHb6YNr92OVtoo1tqi/b5cQ3p1xsEfHSiFhZPw+qm4luiYirI6Jk53u38hHxvoj4cV3+0PnEMGkdc5Qv3fEtZAxTaQNL8L0cwlhYhBgm7kcmHEsL0YYuxDCN93ICpTdYn7i8/djOvqULMbSxXRUqasMCrr84hj6Ox5liYJE/8xdiPE5aRxvjqWv9OJ82TGDBPiea1tGF8Xg3kx6yW+wHw7j0aO9jGEIbuhDDENrQhRiG0IahxFD6oPDiC/Mpbz8u3voXOgb7cRj92EYM0y5vDN3ZJhar/I7q6Fo/dv4IHLNc9jMzL6I6b3WhyxvDcNrQhRiG0IYuxDCENgwlhi6wH6e//rZimHY7pr3+tmIYQjumXd4Y2mvDEHSqH/uQwN0ZEftFxG5U91i4aGTePRehvDG0U94Y2ilvDO2UN4aW6oiIIwrXc8NClK8t+X5suv6uxNC0ji60oQsxNK1jINvl1PtxIDFMfZtoYzx2YLtsYyzcZabDcl16MIxLj/Y+hiG0oQsxDKENXYhhCG0YUAxdOOXFfmynDV2IwX4cQD+2FMMQtuvex9CRbWLBTo2coPzU+/Fu9TXtkMV40PNLjw4lhiG0oQsxDKENXYhhCG0YQgx04IPZfmytD6Yeg/04nH5sqS97vV0PJYZpbxMtbVNT3y7bGAvbH727jcBsYgCXHh1CDENoQxdiGEIbuhDDENrQ9Rgi4kfAv8xWLjOfOUe9jcpPYsj92HT9XYmhaR1daEMXYmhax1LaLoe+j+5C+S58TvRluywtv/N8V9BBnb306BKLYQht6EIMQ2hDF2IYQhu6HsM24G0N6m1afhJD7sem6+9KDE3r6EIbuhBD0zqW0nY59H10F8p34XOiL9tlUfkhJXBNDyW2cSjSGIbRhi7EMIQ2dCGGIbSh6zH8NDMvaVBv0/KTGHI/Nl1/V2JoWkcX2tCFGJrWsZS2y6Hvo7tQvgufE33ZLovK9+EqlJKk7rolIvbd/iIiToyIf4qIMyJi70UoPxRd6IcuxNBUF9rQhRiaGkIb1B1d+JwY1JjufAI3hEuPDiGGIbShCzEMoQ1diGEIbRhKDMCewO11XY8HTgfOBW4F1hXU27S8/djO+jsRg/04jH5sI4ZplzeGdsrXpv450bSOjvTjXZpekWWhHwzgyjVDiGEIbehCDENoQxdiGEIbBhTDVSPPzwTeMNO8hSpvP7bahi7EYD8OoB9bimEI23XvY+jINtHGeJzqdtlGP44+On8ETpLUaTtHxPbfUx8JfGZ03iKUH4ou9EMXYmiqC23oQgxNDaEN6o4ufE4Makz3IeAHRcT62Wbm3Jf9bFreGNopbwztlDeGdsobQ3t1fAS4JCJ+APwc+DxARDyE6tSUuTQtD/ZjG+vvSgz24zD6sY0Ypl3eGNopD934nJj2dtlGP/5aHxK4IVx6dAgxDKENXYhhCG3oQgxDaMMgYsjMv4qIi4H9gE9lfa4I1W+sX77Q5WtLvh+brr8rMTStowtt6EIMTesYyHY59X4cSAxT3ybaGI8d2C5bvVV3ulsAAARjSURBVI1BHxK4IVx6dAgxDKENXYhhCG3oQgxDaMNQYiAzL51h2jcXqzz2Yyvr70gM9uMw+rGNGKZd3hjaKQ904nNi2ttlq7cx6MNv4IZw6dEhxDCENnQhhiG0oQsxDKENQ4mhC+zH6a+/rRim3Y5pr7+tGIbQjmmXN4b22jAEnerHPiRwvb/06EBiGEIbuhDDENrQhRiG0IahxNAF9uP0199WDNNux7TX31YMQ2jHtMsbQ3ttGIJu9WO2eEnLhXgwjEuP9j6GIbShCzEMoQ1diGEIbRhKDF142I/TX7/92K0YhtCOaZc3hu6MpS48utaPfTgCN4RLjw4hhiG0oQsxDKENXYhhCG0YSgxdYD9Of/1txTDtdkx7/W3FMIR2TLu8MbRTfig61Y996PghXHp0CDEMoQ1diGEIbehCDENow1Bi6AL7cfrrbyuGabdj2utvK4YhtGPa5Y2hvTYMQaf6MepDd50WEUdw12U/f1ZPeyiwR2ZeudDljWE4behCDENoQxdiGEIbhhJDF9iP019/WzFMux3TXn9bMQyhHdMubwzttWEIutSPvUjgJEmSJEn9uAqlJEmSJAkTOEmSJEnqDRM4SZIkSeqJPlyFUpIkIuJXwDVUn13fBp4PbADuAewN3BO4qV7894HPAT+pXy8DPga8KTN/MUv9OwFvB54MJPAfwHOA82ZbR2beMEM9ewBvA55S1/FD4NWZedlIG3YB7gA+ALw9M++ctD8kSUuTCZwkqS9+npmPBoiIDwCnZOZj69cvBFZl5qnbF44IgCdl5g/qpGpd/XjBLPU/F3gA8MjMvDMi9gd+tqN1zOJsqgRzZV3Pg4CHz9CG+wP/G/gt4PXl3SBJWspM4CRJffQl4JGlC2fmTyPiZODGiNg7M/99hsX2A7ZuPxqWmVsmDSoiHgw8FvhvI/VcD1w/Q0zfj4g1wOUR8Yb0stCSpAL+Bk6S1CsRsQw4Elg/SbnM/DH1kbFZFvko8IyIuCoi3hYRh84jvEcAV2Xmrwpjup7qs/j+81iXJGkJMoGTJPXFPSPiKqrflO0NfHoedcRsM+ojbg8DXgvcCVwcEUfOJ9C2YpIkaZwJnCSpL7b/fuyBwK7AKZMUjoh7AwcC35xtmcz8RWZ+IjNfDbyZ6mIok9gEPKq+IEpJTA8CfgV8f8L1SJKWKBM4SVKvZOatwJ8Cr4qIXUrK1BcxeTfw8cy8ZZZlDouIB9TPd6L6jd13JoztW8BG4I1RX0UlIlZGxOoZ1rcPsBZ4l79/kySVMoGTJPVOZn4F+Cpw3ByLfjYivgZ8Gfgu8LIdLHt/4J/r5a+musz/u+YR3kuAfYHNEXEN8B7g5nrePevf2G0CLgI+BbxxHuuQJC1R4T/9JEmSJKkfPAInSZIkST3hfeAkSUtKRPwO8MGxyb/YfsPuCeq5DLjH2OTnZ+Y1TeKTJGlHPIVSkiRJknrCUyglSZIkqSdM4CRJkiSpJ0zgJEmSJKknTOAkSZIkqSf+P9tkqgUofAFhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.groupby(\"RTD_ST_CD\")[\"Call_Flag\"].mean().sort_values().plot(kind=\"bar\", figsize=(15,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129277, 23)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['CHANNEL1_6M','CHANNEL2_6M','CHANNEL3_6M','CHANNEL5_6M','METHOD1_3M'], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.columns[(data == 0).all()][0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "Different encoding methods, 1) simple mapping 2) Dummies encoding 3) Hashing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_data = data.select_dtypes(include=['object']).copy()\n",
    "obj_data.head()\n",
    "\n",
    "# 1) FIND AND REPLACE:\n",
    "cleanup_nums = {\"RTD_ST_CD\":     {\"ST_S1\": 1, \"ST_S2\": 2, \"ST_S3\": 3, \"ST_S4\": 4,\"ST_S5\": 5, \"ST_S6\": 6,\n",
    "                                 \"ST_S7\": 7, \"ST_S8\": 8,\"ST_S9\": 9, \"ST_S10\": 10,\"ST_S11\": 11, \"ST_S12\": 12,\n",
    "                                 \"ST_S13\": 13, \"ST_S14\": 14,\"ST_S15\": 15, \"ST_S16\": 16,\"ST_S17\": 17, \"ST_S18\": 18,\n",
    "                                 \"ST_S19\": 19, \"ST_S20\": 20,\"ST_S21\": 21, \"ST_S22\": 22,\"ST_S23\": 23, \"ST_S24\": 24,\n",
    "                                 \"ST_S25\": 25, \"ST_S26\": 26,\"ST_S27\": 27, \"ST_S28\": 28,\"ST_S29\": 29, \"ST_S30\": 30,\n",
    "                                 \"ST_S31\": 31, \"ST_S32\": 32,\"ST_S33\": 33, \"ST_S34\": 34,\"ST_S35\": 35, \"ST_S36\": 36,\n",
    "                                 \"ST_S37\": 37, \"ST_S38\": 38,\"ST_S39\": 39, \"ST_S40\": 40,\"ST_S41\": 41, \"ST_S42\": 42,\n",
    "                                 \"ST_S43\": 43, \"ST_S44\": 44,\"ST_S45\": 45, \"ST_S46\": 46,\"ST_S47\": 47, \"ST_S48\": 48,\n",
    "                                 \"ST_S49\": 49, \"ST_S50\": 50, \"ST_S0\": 0},\n",
    "                \"CustomerSegment\": {\"1\": 1, \"2\": 2, \"3\": 3, \"NONE\": 0},\n",
    "                \"MART_STATUS\": {\"MS_S0\": 0, \"MS_S1\": 1, \"MS_S2\": 2, \"MS_S3\": 3, \"MS_S4\": 4},\n",
    "                \"GENDER\": {\"F\": 1, \"M\": 0}}\n",
    "\n",
    "obj_data.replace(cleanup_nums, inplace=True)\n",
    "obj_data.head()\n",
    "data.replace(cleanup_nums, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>DATE_FOR</th>\n",
       "      <th>RTD_ST_CD_0</th>\n",
       "      <th>RTD_ST_CD_1</th>\n",
       "      <th>RTD_ST_CD_2</th>\n",
       "      <th>RTD_ST_CD_3</th>\n",
       "      <th>RTD_ST_CD_4</th>\n",
       "      <th>RTD_ST_CD_5</th>\n",
       "      <th>RTD_ST_CD_6</th>\n",
       "      <th>RTD_ST_CD_7</th>\n",
       "      <th>...</th>\n",
       "      <th>CHANNEL5_3M</th>\n",
       "      <th>METHOD1_3M</th>\n",
       "      <th>PAYMENTS_3M</th>\n",
       "      <th>NOT_DI_3M</th>\n",
       "      <th>NOT_DI_6M</th>\n",
       "      <th>EVENT1_30_FLAG</th>\n",
       "      <th>EVENT2_90_SUM</th>\n",
       "      <th>LOGINS</th>\n",
       "      <th>POLICYPURCHASECHANNEL</th>\n",
       "      <th>Call_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5/19/2014</td>\n",
       "      <td>-0.980392</td>\n",
       "      <td>-0.960784</td>\n",
       "      <td>-0.941176</td>\n",
       "      <td>-0.921569</td>\n",
       "      <td>-0.901961</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.862745</td>\n",
       "      <td>-0.843137</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5/17/2014</td>\n",
       "      <td>-0.980392</td>\n",
       "      <td>-0.960784</td>\n",
       "      <td>-0.941176</td>\n",
       "      <td>-0.921569</td>\n",
       "      <td>-0.901961</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.862745</td>\n",
       "      <td>-0.843137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5/15/2014</td>\n",
       "      <td>-0.980392</td>\n",
       "      <td>-0.960784</td>\n",
       "      <td>-0.941176</td>\n",
       "      <td>-0.921569</td>\n",
       "      <td>-0.901961</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.862745</td>\n",
       "      <td>-0.843137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5/16/2014</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-0.960784</td>\n",
       "      <td>-0.941176</td>\n",
       "      <td>-0.921569</td>\n",
       "      <td>-0.901961</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.862745</td>\n",
       "      <td>-0.843137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5/20/2014</td>\n",
       "      <td>-0.980392</td>\n",
       "      <td>-0.960784</td>\n",
       "      <td>-0.941176</td>\n",
       "      <td>-0.921569</td>\n",
       "      <td>-0.901961</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.862745</td>\n",
       "      <td>-0.843137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130081</th>\n",
       "      <td>1</td>\n",
       "      <td>5/17/2014</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130082</th>\n",
       "      <td>1</td>\n",
       "      <td>5/19/2014</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130083</th>\n",
       "      <td>1</td>\n",
       "      <td>5/16/2014</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130084</th>\n",
       "      <td>1</td>\n",
       "      <td>5/15/2014</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130085</th>\n",
       "      <td>1</td>\n",
       "      <td>5/19/2014</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130086 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        intercept   DATE_FOR  RTD_ST_CD_0  RTD_ST_CD_1  RTD_ST_CD_2  \\\n",
       "0               1  5/19/2014    -0.980392    -0.960784    -0.941176   \n",
       "1               1  5/17/2014    -0.980392    -0.960784    -0.941176   \n",
       "2               1  5/15/2014    -0.980392    -0.960784    -0.941176   \n",
       "3               1  5/16/2014     0.019608    -0.960784    -0.941176   \n",
       "4               1  5/20/2014    -0.980392    -0.960784    -0.941176   \n",
       "...           ...        ...          ...          ...          ...   \n",
       "130081          1  5/17/2014     0.019608     0.039216     0.058824   \n",
       "130082          1  5/19/2014     0.019608     0.039216     0.058824   \n",
       "130083          1  5/16/2014     0.019608     0.039216     0.058824   \n",
       "130084          1  5/15/2014     0.019608     0.039216     0.058824   \n",
       "130085          1  5/19/2014     0.019608     0.039216     0.058824   \n",
       "\n",
       "        RTD_ST_CD_3  RTD_ST_CD_4  RTD_ST_CD_5  RTD_ST_CD_6  RTD_ST_CD_7  ...  \\\n",
       "0         -0.921569    -0.901961    -0.882353    -0.862745    -0.843137  ...   \n",
       "1         -0.921569    -0.901961    -0.882353    -0.862745    -0.843137  ...   \n",
       "2         -0.921569    -0.901961    -0.882353    -0.862745    -0.843137  ...   \n",
       "3         -0.921569    -0.901961    -0.882353    -0.862745    -0.843137  ...   \n",
       "4         -0.921569    -0.901961    -0.882353    -0.862745    -0.843137  ...   \n",
       "...             ...          ...          ...          ...          ...  ...   \n",
       "130081     0.078431     0.098039     0.117647     0.137255     0.156863  ...   \n",
       "130082     0.078431     0.098039     0.117647     0.137255     0.156863  ...   \n",
       "130083     0.078431     0.098039     0.117647     0.137255     0.156863  ...   \n",
       "130084     0.078431     0.098039     0.117647     0.137255     0.156863  ...   \n",
       "130085     0.078431     0.098039     0.117647     0.137255     0.156863  ...   \n",
       "\n",
       "        CHANNEL5_3M  METHOD1_3M  PAYMENTS_3M  NOT_DI_3M  NOT_DI_6M  \\\n",
       "0                 2           0            3          0          0   \n",
       "1                 0           3            3          0          0   \n",
       "2                 0           0            6          0          0   \n",
       "3                 0           0            0          0          0   \n",
       "4                 0           0            1          0          0   \n",
       "...             ...         ...          ...        ...        ...   \n",
       "130081            0           0            1          0          0   \n",
       "130082            0           0            2          0          0   \n",
       "130083            0           0            1          0          0   \n",
       "130084            0           0            1          0          0   \n",
       "130085            0           2            2          0          0   \n",
       "\n",
       "        EVENT1_30_FLAG  EVENT2_90_SUM  LOGINS  POLICYPURCHASECHANNEL  \\\n",
       "0                    0              0       0                      0   \n",
       "1                    0              0       0                      0   \n",
       "2                    0              0       0                      0   \n",
       "3                    0              0       0                      1   \n",
       "4                    0              0       0                      0   \n",
       "...                ...            ...     ...                    ...   \n",
       "130081               0              0       0                      0   \n",
       "130082               0              0       0                      0   \n",
       "130083               0              0       0                      0   \n",
       "130084               0              0       0                      0   \n",
       "130085               0              0       0                      0   \n",
       "\n",
       "        Call_Flag  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "130081          0  \n",
       "130082          0  \n",
       "130083          0  \n",
       "130084          0  \n",
       "130085          0  \n",
       "\n",
       "[130086 rows x 84 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature representation with imputing unknown variabl \n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.backward_difference.BackwardDifferenceEncoder(cols=['RTD_ST_CD','MART_STATUS', 'CustomerSegment','GENDER'])\n",
    "encoder.fit(data, verbose=1)\n",
    "\n",
    "enc_Back = encoder.transform(data)\n",
    "enc_Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_enc = ce.HashingEncoder(cols=['RTD_ST_CD','MART_STATUS', 'CustomerSegment','GENDER'])\n",
    "hash_enc.fit(data)\n",
    "enc_data = hash_enc.transform(data)\n",
    "input_dimension = enc_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_all = enc_data.drop(\"Call_Flag\", axis=1)\n",
    "y_all = data[\"Call_Flag\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_all, y_all,test_size=0.2,random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (103421, 25)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "binary_features = ['col_0','col_1','col_2','col_5','col_6','col_7','RECENT_PAYMENT','NOT_DI_6M','NOT_DI_3M','POLICYPURCHASECHANNEL']\n",
    "\n",
    "X_train_n = X_train.drop(binary_features, axis=1)\n",
    "data_train_numpy = X_train_n.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data_scaled = min_max_scaler.fit_transform(data_train_numpy)\n",
    "data_train_normal = pd.DataFrame(data_scaled)\n",
    "data_train_normal = pd.concat([data_train_normal.reset_index(), X_train.loc[:,binary_features].reset_index()], axis=1)\n",
    "data_train_normal = data_train_normal.drop(['index'],axis=1)\n",
    "print('train data shape:', data_train_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data shape: (25856, 25)\n"
     ]
    }
   ],
   "source": [
    "X_test_n = X_test.drop(binary_features, axis=1)\n",
    "data_test_numpy = X_test_n.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data_scaled = min_max_scaler.fit_transform(data_test_numpy)\n",
    "data_test_normal = pd.DataFrame(data_scaled)\n",
    "\n",
    "data_test_normal = pd.concat([data_test_normal.reset_index(),X_test[binary_features].reset_index()], axis=1)\n",
    "data_test_normal = data_test_normal.drop(['index'],axis=1)\n",
    "print('test data shape:', data_test_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the packges for running this model and Guassain Process hyperparameter-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Conv1D,MaxPooling1D\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "import skopt\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_evaluations\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has four fully connected layers. Activation function for each of the neurons in those layers is \"ReLu\". However, the last layer's activation function is \"sigmoid\" since wr are solving a binary classification problem. The optimization function applied is \"Adam\" with decay rate equal to 1e-6 to changing the learning rate in each step of the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate,num_dense_one,num_dense_two,\n",
    "                 num_dense_four,dropout_two):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    \"\"\"\n",
    "    model = tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Dense(num_dense_one,input_dim=25,activation='relu'),\n",
    "    tf.keras.layers.Dense(num_dense_two ,activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout_two),\n",
    "    #tf.keras.layers.Dense(num_dense_three,activation='relu'),\n",
    "    #tf.keras.layers.Dropout(dropout_three),\n",
    "    tf.keras.layers.Dense(num_dense_four ,activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "          ])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=learning_rate, decay=1e-6)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function for saving weights of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dir_name(learning_rate, num_flt_one,\n",
    "                 num_flt_two):\n",
    "\n",
    "    # The dir-name for the TensorBoard log-dir.\n",
    "    s = \"./19_logs/lr_{0:.0e}_#flt_one_{1}_flt_two_{2}_/\"\n",
    "\n",
    "    # Insert all the hyper-parameters in the dir-name.\n",
    "    log_dir = s.format(learning_rate,\n",
    "                       num_flt_one,\n",
    "                       num_flt_two)\n",
    "\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining hyperparameters along their ranges and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the range that learning rate start at the begining of the training\n",
    "learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                         name='learning_rate')\n",
    "# The range that number of neurons in the first layer can varies\n",
    "num_dense_one = Integer(low=18, high=22, name='num_dense_one')\n",
    "# The range that number of neurons in the second layer can varies\n",
    "num_dense_two = Integer(low=12, high=20, name='num_dense_two')\n",
    "# The range that number of neurons in the third layer can varies\n",
    "#num_dense_three = Integer(low=10, high=15, name='num_dense_three')\n",
    "# The range that number of neurons in the rourth layer can varies\n",
    "num_dense_four = Integer(low=4, high=12, name='num_dense_four')\n",
    "# The range that weight for penalizing the majority class can varies\n",
    "weight = Categorical([1.0,5.0,10.0,15.0,20.0,25], name='weight')\n",
    "# Dropout range for the second layer\n",
    "dropout_two = Real(low=0.0, high=0.2,\n",
    "                         name='dropout_two')\n",
    "#Dropout layer for the third layer\n",
    "#dropout_three = Real(low=0.0, high=0.2,\n",
    "#                         name='dropout_three')\n",
    "#vector of hyperparameters\n",
    "dimensions = [learning_rate, num_dense_one, num_dense_two,\n",
    "              num_dense_four,dropout_two,weight]\n",
    "#vector of default values for hyperparameters\n",
    "default_parameters = [1e-4, 22, 18,6,0.0,5]\n",
    "#name of the file saving the weights of the best network\n",
    "path_best_model = 'best_model.h5'\n",
    "#the golobal variable for controling the accuracy in hypertinning process\n",
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the wrapper for functin ran for each candidate point of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "\n",
    "def fitness(learning_rate,num_dense_one,num_dense_two,\n",
    "            num_dense_four,dropout_two,weight):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    \n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    \n",
    "    print('# nodes layer 1 : ', num_dense_one)\n",
    "    \n",
    "    print('# nodes layer 2: ', num_dense_two)\n",
    "    print('Dropout layer 2: ', dropout_two)\n",
    "    \n",
    "    #print('# nodes layer 3: ', num_dense_three)\n",
    "    #print('Dropout layer 2: ', dropout_three)\n",
    "    \n",
    "    print('# nodes layer 4: ', num_dense_four)\n",
    "    \n",
    "    print('weight: ', weight)\n",
    "    print()\n",
    "    \n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = create_model(learning_rate,num_dense_one,num_dense_two,\n",
    "                         num_dense_four, dropout_two)\n",
    "    \n",
    "    log_dir = log_dir_name(learning_rate, num_dense_one,\n",
    "                 num_dense_two)\n",
    "    #using tensorboard for saving the graphs of computaion and metrics\n",
    "    callback_log = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False)\n",
    "    es = EarlyStopping(monitor='val_acc', mode='auto', verbose=1, patience=5)\n",
    "    # Use Keras to train the model.\n",
    "    weights = {0: 1.,\n",
    "           1: weight}\n",
    "    history = model.fit(x=data_train_normal,\n",
    "                        y=y_train,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=20,\n",
    "                        batch_size=128,\n",
    "                        class_weight=weights,\n",
    "                        callbacks=[es, callback_log])\n",
    "\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_acc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    # If the classification accuracy of the saved model is improved ...\n",
    "    if accuracy > best_accuracy:\n",
    "        # Save the new model to harddisk.\n",
    "        model.save(path_best_model)\n",
    "        \n",
    "        # Update the classification accuracy.\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    \n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hypertunning process searches among 20 vectors of hyperparameters. Each time a vector by GP(Guassian Process) is suggested\n",
    "except the first time where the process gives the default vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Gaussian process for finding the best hyperparapeters (searching among 30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-04\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  18\n",
      "Dropout layer 2:  0.0\n",
      "# nodes layer 4:  6\n",
      "weight:  5\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.5085 - acc: 0.9626 - val_loss: 0.4238 - val_acc: 0.9629\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.4098 - acc: 0.9638 - val_loss: 0.4093 - val_acc: 0.9629\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.3935 - acc: 0.9638 - val_loss: 0.3943 - val_acc: 0.9629\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.3779 - acc: 0.9638 - val_loss: 0.3808 - val_acc: 0.9625\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.3642 - acc: 0.9630 - val_loss: 0.3685 - val_acc: 0.9609\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.3519 - acc: 0.9604 - val_loss: 0.3567 - val_acc: 0.9578\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Accuracy: 95.78%\n",
      "\n",
      "learning rate: 2.7e-06\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  14\n",
      "Dropout layer 2:  0.06473657619308183\n",
      "# nodes layer 4:  7\n",
      "weight:  10.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 30us/sample - loss: 0.6603 - acc: 0.9638 - val_loss: 0.6613 - val_acc: 0.9629\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6575 - acc: 0.9638 - val_loss: 0.6586 - val_acc: 0.9629\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6544 - acc: 0.9638 - val_loss: 0.6557 - val_acc: 0.9629\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6515 - acc: 0.9638 - val_loss: 0.6521 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6487 - acc: 0.9638 - val_loss: 0.6491 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6454 - acc: 0.9638 - val_loss: 0.6465 - val_acc: 0.9629\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 1.9e-05\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  19\n",
      "Dropout layer 2:  0.02320983189324249\n",
      "# nodes layer 4:  4\n",
      "weight:  20.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 30us/sample - loss: 0.6908 - acc: 0.8517 - val_loss: 0.6887 - val_acc: 0.9003\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6870 - acc: 0.9413 - val_loss: 0.6847 - val_acc: 0.9615\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6828 - acc: 0.9626 - val_loss: 0.6818 - val_acc: 0.9628\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6776 - acc: 0.9636 - val_loss: 0.6763 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6726 - acc: 0.9638 - val_loss: 0.6708 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6695 - acc: 0.9638 - val_loss: 0.6691 - val_acc: 0.9629\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6669 - acc: 0.9638 - val_loss: 0.6667 - val_acc: 0.9629\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6651 - acc: 0.9638 - val_loss: 0.6662 - val_acc: 0.9629\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6632 - acc: 0.9638 - val_loss: 0.6647 - val_acc: 0.9629\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 7.6e-04\n",
      "# nodes layer 1 :  18\n",
      "# nodes layer 2:  18\n",
      "Dropout layer 2:  0.1321531040345911\n",
      "# nodes layer 4:  10\n",
      "weight:  10.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 30us/sample - loss: 0.5289 - acc: 0.9444 - val_loss: 0.4605 - val_acc: 0.9285\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4355 - acc: 0.9117 - val_loss: 0.4324 - val_acc: 0.9035\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4203 - acc: 0.9023 - val_loss: 0.4243 - val_acc: 0.9072\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4135 - acc: 0.9010 - val_loss: 0.4332 - val_acc: 0.9165\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4087 - acc: 0.9023 - val_loss: 0.4263 - val_acc: 0.9108\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.4061 - acc: 0.9034 - val_loss: 0.4239 - val_acc: 0.8960\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Accuracy: 89.60%\n",
      "\n",
      "learning rate: 2.1e-04\n",
      "# nodes layer 1 :  19\n",
      "# nodes layer 2:  14\n",
      "Dropout layer 2:  0.11612289729902976\n",
      "# nodes layer 4:  9\n",
      "weight:  10.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5700 - acc: 0.9614 - val_loss: 0.5457 - val_acc: 0.9629\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.5267 - acc: 0.9612 - val_loss: 0.5090 - val_acc: 0.9535\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4896 - acc: 0.9457 - val_loss: 0.4719 - val_acc: 0.9336\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4603 - acc: 0.9309 - val_loss: 0.4516 - val_acc: 0.9242\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4418 - acc: 0.9176 - val_loss: 0.4413 - val_acc: 0.9206\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4324 - acc: 0.9110 - val_loss: 0.4340 - val_acc: 0.9066\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Accuracy: 90.66%\n",
      "\n",
      "learning rate: 9.3e-06\n",
      "# nodes layer 1 :  20\n",
      "# nodes layer 2:  13\n",
      "Dropout layer 2:  0.049660026708498374\n",
      "# nodes layer 4:  7\n",
      "weight:  15.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 31us/sample - loss: 0.7545 - acc: 0.0582 - val_loss: 0.7372 - val_acc: 0.0377\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7334 - acc: 0.0733 - val_loss: 0.7196 - val_acc: 0.0666\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7164 - acc: 0.1600 - val_loss: 0.7054 - val_acc: 0.2615\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7038 - acc: 0.3867 - val_loss: 0.6944 - val_acc: 0.5599\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6944 - acc: 0.6166 - val_loss: 0.6860 - val_acc: 0.7628\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6864 - acc: 0.7473 - val_loss: 0.6799 - val_acc: 0.8470\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6795 - acc: 0.8363 - val_loss: 0.6740 - val_acc: 0.9301\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6743 - acc: 0.8857 - val_loss: 0.6694 - val_acc: 0.9435\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - ETA: 0s - loss: 0.6686 - acc: 0.909 - 2s 27us/sample - loss: 0.6685 - acc: 0.9096 - val_loss: 0.6649 - val_acc: 0.9569\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6645 - acc: 0.9264 - val_loss: 0.6612 - val_acc: 0.9612\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6609 - acc: 0.9369 - val_loss: 0.6592 - val_acc: 0.9616\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6572 - acc: 0.9445 - val_loss: 0.6558 - val_acc: 0.9622\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6548 - acc: 0.9514 - val_loss: 0.6532 - val_acc: 0.9629\n",
      "Epoch 14/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6515 - acc: 0.9553 - val_loss: 0.6514 - val_acc: 0.9629\n",
      "Epoch 15/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6486 - acc: 0.9561 - val_loss: 0.6475 - val_acc: 0.9629\n",
      "Epoch 16/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6461 - acc: 0.9581 - val_loss: 0.6473 - val_acc: 0.9629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6447 - acc: 0.9590 - val_loss: 0.6454 - val_acc: 0.9629\n",
      "Epoch 18/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6432 - acc: 0.9594 - val_loss: 0.6425 - val_acc: 0.9629\n",
      "Epoch 00018: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 9.1e-03\n",
      "# nodes layer 1 :  19\n",
      "# nodes layer 2:  16\n",
      "Dropout layer 2:  0.13104006381036515\n",
      "# nodes layer 4:  10\n",
      "weight:  15.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 30us/sample - loss: 0.4937 - acc: 0.8629 - val_loss: 0.4654 - val_acc: 0.8530\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4554 - acc: 0.8616 - val_loss: 0.4613 - val_acc: 0.8474\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4499 - acc: 0.8605 - val_loss: 0.4696 - val_acc: 0.8641\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.4466 - acc: 0.8544 - val_loss: 0.4679 - val_acc: 0.8665\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.4432 - acc: 0.8601 - val_loss: 0.4585 - val_acc: 0.8699\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.4428 - acc: 0.8683 - val_loss: 0.4678 - val_acc: 0.9061\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4430 - acc: 0.8758 - val_loss: 0.4616 - val_acc: 0.8649\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4400 - acc: 0.8569 - val_loss: 0.4841 - val_acc: 0.9092\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4399 - acc: 0.8593 - val_loss: 0.4632 - val_acc: 0.8738\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.4401 - acc: 0.8664 - val_loss: 0.4611 - val_acc: 0.8715\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4391 - acc: 0.8604 - val_loss: 0.4577 - val_acc: 0.8701\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4356 - acc: 0.8658 - val_loss: 0.4588 - val_acc: 0.8772\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4370 - acc: 0.8673 - val_loss: 0.4564 - val_acc: 0.8821\n",
      "Epoch 00013: early stopping\n",
      "\n",
      "Accuracy: 88.21%\n",
      "\n",
      "learning rate: 5.9e-03\n",
      "# nodes layer 1 :  19\n",
      "# nodes layer 2:  13\n",
      "Dropout layer 2:  0.021458947504673215\n",
      "# nodes layer 4:  7\n",
      "weight:  5.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 30us/sample - loss: 0.3506 - acc: 0.9539 - val_loss: 0.3477 - val_acc: 0.9004\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.3176 - acc: 0.9437 - val_loss: 0.3274 - val_acc: 0.9435\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.3126 - acc: 0.9466 - val_loss: 0.3260 - val_acc: 0.9554\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.3084 - acc: 0.9463 - val_loss: 0.3201 - val_acc: 0.9340\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.3064 - acc: 0.9465 - val_loss: 0.3187 - val_acc: 0.9487\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.3058 - acc: 0.9451 - val_loss: 0.3207 - val_acc: 0.9386\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.3049 - acc: 0.9472 - val_loss: 0.3195 - val_acc: 0.9485\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.3034 - acc: 0.9471 - val_loss: 0.3181 - val_acc: 0.9474\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Accuracy: 94.74%\n",
      "\n",
      "learning rate: 8.1e-03\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  18\n",
      "Dropout layer 2:  0.10124587642433854\n",
      "# nodes layer 4:  8\n",
      "weight:  20.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 31us/sample - loss: 0.5189 - acc: 0.8304 - val_loss: 0.4887 - val_acc: 0.8141\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4757 - acc: 0.8137 - val_loss: 0.4869 - val_acc: 0.7831\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4704 - acc: 0.8075 - val_loss: 0.4854 - val_acc: 0.8186\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4631 - acc: 0.8187 - val_loss: 0.4846 - val_acc: 0.8410\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4631 - acc: 0.8193 - val_loss: 0.4752 - val_acc: 0.8251\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4586 - acc: 0.8227 - val_loss: 0.4812 - val_acc: 0.8426\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4550 - acc: 0.8247 - val_loss: 0.4805 - val_acc: 0.8284\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4553 - acc: 0.8228 - val_loss: 0.4893 - val_acc: 0.8501\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.4542 - acc: 0.8187 - val_loss: 0.4838 - val_acc: 0.8141\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.4536 - acc: 0.8203 - val_loss: 0.4788 - val_acc: 0.7844\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.4515 - acc: 0.8196 - val_loss: 0.4864 - val_acc: 0.8191\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.4488 - acc: 0.8243 - val_loss: 0.4766 - val_acc: 0.7706\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.4514 - acc: 0.8152 - val_loss: 0.4778 - val_acc: 0.8380\n",
      "Epoch 00013: early stopping\n",
      "\n",
      "Accuracy: 83.80%\n",
      "\n",
      "learning rate: 9.4e-06\n",
      "# nodes layer 1 :  18\n",
      "# nodes layer 2:  14\n",
      "Dropout layer 2:  0.05887271392726576\n",
      "# nodes layer 4:  8\n",
      "weight:  10.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6130 - acc: 0.9638 - val_loss: 0.6146 - val_acc: 0.9629\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6042 - acc: 0.9638 - val_loss: 0.6051 - val_acc: 0.9629\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5964 - acc: 0.9638 - val_loss: 0.5979 - val_acc: 0.9629\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5893 - acc: 0.9638 - val_loss: 0.5937 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5846 - acc: 0.9638 - val_loss: 0.5897 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5804 - acc: 0.9638 - val_loss: 0.5848 - val_acc: 0.9629\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 1.3e-03\n",
      "# nodes layer 1 :  21\n",
      "# nodes layer 2:  17\n",
      "Dropout layer 2:  0.1169828427694579\n",
      "# nodes layer 4:  8\n",
      "weight:  25\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 30us/sample - loss: 0.6156 - acc: 0.8693 - val_loss: 0.5665 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4995 - acc: 0.7880 - val_loss: 0.5324 - val_acc: 0.8538\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4826 - acc: 0.7860 - val_loss: 0.5135 - val_acc: 0.8377\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.4829 - acc: 0.7808 - val_loss: 0.4967 - val_acc: 0.7881\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.4795 - acc: 0.7835 - val_loss: 0.4934 - val_acc: 0.7855\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4741 - acc: 0.7837 - val_loss: 0.4975 - val_acc: 0.8095\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Accuracy: 80.95%\n",
      "\n",
      "learning rate: 1.0e-06\n",
      "# nodes layer 1 :  18\n",
      "# nodes layer 2:  14\n",
      "Dropout layer 2:  0.0\n",
      "# nodes layer 4:  9\n",
      "weight:  10.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6931 - acc: 0.4062 - val_loss: 0.6927 - val_acc: 0.4319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6927 - acc: 0.4584 - val_loss: 0.6922 - val_acc: 0.4922\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6922 - acc: 0.5358 - val_loss: 0.6918 - val_acc: 0.5844\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6918 - acc: 0.6357 - val_loss: 0.6914 - val_acc: 0.6826\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6913 - acc: 0.7120 - val_loss: 0.6909 - val_acc: 0.7351\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.6909 - acc: 0.7576 - val_loss: 0.6905 - val_acc: 0.7748\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6904 - acc: 0.7903 - val_loss: 0.6900 - val_acc: 0.7982\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6899 - acc: 0.8090 - val_loss: 0.6896 - val_acc: 0.8155\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6895 - acc: 0.8228 - val_loss: 0.6891 - val_acc: 0.8277\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6890 - acc: 0.8325 - val_loss: 0.6886 - val_acc: 0.8366\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6884 - acc: 0.8408 - val_loss: 0.6881 - val_acc: 0.8445\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6880 - acc: 0.8494 - val_loss: 0.6877 - val_acc: 0.8530\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6874 - acc: 0.8586 - val_loss: 0.6871 - val_acc: 0.8636\n",
      "Epoch 14/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6869 - acc: 0.8695 - val_loss: 0.6867 - val_acc: 0.8748\n",
      "Epoch 15/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6864 - acc: 0.8814 - val_loss: 0.6861 - val_acc: 0.8876\n",
      "Epoch 16/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.6858 - acc: 0.8937 - val_loss: 0.6856 - val_acc: 0.9017\n",
      "Epoch 17/20\n",
      "82736/82736 [==============================] - 2s 21us/sample - loss: 0.6852 - acc: 0.9095 - val_loss: 0.6850 - val_acc: 0.9163\n",
      "Epoch 18/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.6847 - acc: 0.9222 - val_loss: 0.6844 - val_acc: 0.9253\n",
      "Epoch 19/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.6840 - acc: 0.9317 - val_loss: 0.6838 - val_acc: 0.9340\n",
      "Epoch 20/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6835 - acc: 0.9387 - val_loss: 0.6832 - val_acc: 0.9399\n",
      "\n",
      "Accuracy: 93.99%\n",
      "\n",
      "learning rate: 1.7e-06\n",
      "# nodes layer 1 :  20\n",
      "# nodes layer 2:  18\n",
      "Dropout layer 2:  0.0\n",
      "# nodes layer 4:  10\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.5650 - acc: 0.9546 - val_loss: 0.5619 - val_acc: 0.9565\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.5565 - acc: 0.9599 - val_loss: 0.5532 - val_acc: 0.9615\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.5477 - acc: 0.9632 - val_loss: 0.5445 - val_acc: 0.9626\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.5388 - acc: 0.9638 - val_loss: 0.5356 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.5298 - acc: 0.9638 - val_loss: 0.5266 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.5207 - acc: 0.9638 - val_loss: 0.5175 - val_acc: 0.9629\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.5115 - acc: 0.9638 - val_loss: 0.5083 - val_acc: 0.9629\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.5023 - acc: 0.9638 - val_loss: 0.4991 - val_acc: 0.9629\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.4930 - acc: 0.9638 - val_loss: 0.4899 - val_acc: 0.9629\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 1.0e-06\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.04136083178400049\n",
      "# nodes layer 4:  12\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 29us/sample - loss: 0.5553 - acc: 0.9638 - val_loss: 0.5541 - val_acc: 0.9629\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5504 - acc: 0.9638 - val_loss: 0.5491 - val_acc: 0.9629\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5454 - acc: 0.9638 - val_loss: 0.5440 - val_acc: 0.9629\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5402 - acc: 0.9638 - val_loss: 0.5389 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5349 - acc: 0.9638 - val_loss: 0.5336 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 29us/sample - loss: 0.5297 - acc: 0.9638 - val_loss: 0.5283 - val_acc: 0.9629\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 3.0e-06\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.2\n",
      "# nodes layer 4:  11\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 31us/sample - loss: 0.6136 - acc: 0.9187 - val_loss: 0.6077 - val_acc: 0.9401\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6004 - acc: 0.9357 - val_loss: 0.5944 - val_acc: 0.9492\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5875 - acc: 0.9469 - val_loss: 0.5808 - val_acc: 0.9544\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5738 - acc: 0.9526 - val_loss: 0.5670 - val_acc: 0.9589\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5601 - acc: 0.9574 - val_loss: 0.5531 - val_acc: 0.9619\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.5460 - acc: 0.9601 - val_loss: 0.5391 - val_acc: 0.9628\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5318 - acc: 0.9619 - val_loss: 0.5249 - val_acc: 0.9629\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5180 - acc: 0.9627 - val_loss: 0.5106 - val_acc: 0.9629\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5035 - acc: 0.9630 - val_loss: 0.4963 - val_acc: 0.9629\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.4889 - acc: 0.9633 - val_loss: 0.4818 - val_acc: 0.9629\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.4749 - acc: 0.9637 - val_loss: 0.4674 - val_acc: 0.9629\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.4599 - acc: 0.9636 - val_loss: 0.4528 - val_acc: 0.9629\n",
      "Epoch 00012: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 2.2e-06\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.2\n",
      "# nodes layer 4:  4\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 30us/sample - loss: 0.7149 - acc: 0.0653 - val_loss: 0.7098 - val_acc: 0.0784\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7116 - acc: 0.0928 - val_loss: 0.7069 - val_acc: 0.1141\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.7086 - acc: 0.1370 - val_loss: 0.7043 - val_acc: 0.1543\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7057 - acc: 0.1957 - val_loss: 0.7017 - val_acc: 0.2048\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7033 - acc: 0.2665 - val_loss: 0.6994 - val_acc: 0.3066\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7010 - acc: 0.3559 - val_loss: 0.6971 - val_acc: 0.4227\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6987 - acc: 0.4498 - val_loss: 0.6950 - val_acc: 0.5596\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6967 - acc: 0.5397 - val_loss: 0.6931 - val_acc: 0.6965\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6948 - acc: 0.6311 - val_loss: 0.6913 - val_acc: 0.7629\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 29us/sample - loss: 0.6930 - acc: 0.7055 - val_loss: 0.6897 - val_acc: 0.8201\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6913 - acc: 0.7607 - val_loss: 0.6881 - val_acc: 0.8851\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6896 - acc: 0.8100 - val_loss: 0.6867 - val_acc: 0.9149\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6880 - acc: 0.8483 - val_loss: 0.6853 - val_acc: 0.9269\n",
      "Epoch 14/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6865 - acc: 0.8732 - val_loss: 0.6839 - val_acc: 0.9381\n",
      "Epoch 15/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6850 - acc: 0.8919 - val_loss: 0.6825 - val_acc: 0.9540\n",
      "Epoch 16/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6835 - acc: 0.9071 - val_loss: 0.6812 - val_acc: 0.9577\n",
      "Epoch 17/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6820 - acc: 0.9200 - val_loss: 0.6798 - val_acc: 0.9592\n",
      "Epoch 18/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6806 - acc: 0.9283 - val_loss: 0.6784 - val_acc: 0.9603\n",
      "Epoch 19/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6792 - acc: 0.9339 - val_loss: 0.6771 - val_acc: 0.9609\n",
      "Epoch 20/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6777 - acc: 0.9383 - val_loss: 0.6757 - val_acc: 0.9615\n",
      "\n",
      "Accuracy: 96.15%\n",
      "\n",
      "learning rate: 2.1e-06\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  18\n",
      "Dropout layer 2:  0.0\n",
      "# nodes layer 4:  12\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.7195 - acc: 0.2703 - val_loss: 0.7136 - val_acc: 0.3312\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.7081 - acc: 0.3656 - val_loss: 0.7023 - val_acc: 0.4040\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.6968 - acc: 0.4735 - val_loss: 0.6911 - val_acc: 0.5586\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.6857 - acc: 0.6244 - val_loss: 0.6801 - val_acc: 0.6819\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6747 - acc: 0.7322 - val_loss: 0.6691 - val_acc: 0.7795\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.6635 - acc: 0.8172 - val_loss: 0.6578 - val_acc: 0.8494\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 21us/sample - loss: 0.6520 - acc: 0.8770 - val_loss: 0.6462 - val_acc: 0.9009\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 21us/sample - loss: 0.6403 - acc: 0.9205 - val_loss: 0.6344 - val_acc: 0.9361\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.6284 - acc: 0.9423 - val_loss: 0.6224 - val_acc: 0.9464\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.6162 - acc: 0.9498 - val_loss: 0.6102 - val_acc: 0.9523\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6039 - acc: 0.9552 - val_loss: 0.5978 - val_acc: 0.9566\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.5913 - acc: 0.9598 - val_loss: 0.5852 - val_acc: 0.9603\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.5785 - acc: 0.9619 - val_loss: 0.5723 - val_acc: 0.9614\n",
      "Epoch 14/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.5655 - acc: 0.9630 - val_loss: 0.5593 - val_acc: 0.9621\n",
      "Epoch 15/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.5524 - acc: 0.9635 - val_loss: 0.5462 - val_acc: 0.9626\n",
      "Epoch 16/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.5392 - acc: 0.9637 - val_loss: 0.5330 - val_acc: 0.9628\n",
      "Epoch 17/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.5260 - acc: 0.9638 - val_loss: 0.5198 - val_acc: 0.9629\n",
      "Epoch 18/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.5127 - acc: 0.9638 - val_loss: 0.5066 - val_acc: 0.9629\n",
      "Epoch 19/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.4994 - acc: 0.9638 - val_loss: 0.4933 - val_acc: 0.9629\n",
      "Epoch 20/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.4861 - acc: 0.9638 - val_loss: 0.4800 - val_acc: 0.9629\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 2.1e-06\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.06158473738358783\n",
      "# nodes layer 4:  12\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 30us/sample - loss: 0.5943 - acc: 0.9638 - val_loss: 0.5925 - val_acc: 0.9629\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5851 - acc: 0.9638 - val_loss: 0.5830 - val_acc: 0.9629\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.5754 - acc: 0.9638 - val_loss: 0.5730 - val_acc: 0.9629\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5652 - acc: 0.9638 - val_loss: 0.5626 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5545 - acc: 0.9638 - val_loss: 0.5518 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5435 - acc: 0.9638 - val_loss: 0.5405 - val_acc: 0.9629\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 2.0e-06\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.0\n",
      "# nodes layer 4:  12\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7104 - acc: 0.3994 - val_loss: 0.7051 - val_acc: 0.4643\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.7000 - acc: 0.5116 - val_loss: 0.6948 - val_acc: 0.5659\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6897 - acc: 0.6097 - val_loss: 0.6845 - val_acc: 0.6622\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6795 - acc: 0.7008 - val_loss: 0.6743 - val_acc: 0.7380\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6693 - acc: 0.7614 - val_loss: 0.6641 - val_acc: 0.7875\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6591 - acc: 0.8110 - val_loss: 0.6538 - val_acc: 0.8332\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6487 - acc: 0.8548 - val_loss: 0.6433 - val_acc: 0.8705\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6381 - acc: 0.8851 - val_loss: 0.6326 - val_acc: 0.8940\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6272 - acc: 0.9067 - val_loss: 0.6217 - val_acc: 0.9140\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6162 - acc: 0.9258 - val_loss: 0.6106 - val_acc: 0.9319\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6052 - acc: 0.9414 - val_loss: 0.5995 - val_acc: 0.9474\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.5941 - acc: 0.9520 - val_loss: 0.5884 - val_acc: 0.9553\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.5830 - acc: 0.9581 - val_loss: 0.5773 - val_acc: 0.9593\n",
      "Epoch 14/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.5720 - acc: 0.9608 - val_loss: 0.5663 - val_acc: 0.9611\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.5610 - acc: 0.9629 - val_loss: 0.5553 - val_acc: 0.9627\n",
      "Epoch 16/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.5499 - acc: 0.9637 - val_loss: 0.5443 - val_acc: 0.9629\n",
      "Epoch 17/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.5389 - acc: 0.9638 - val_loss: 0.5333 - val_acc: 0.9629\n",
      "Epoch 18/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.5279 - acc: 0.9638 - val_loss: 0.5223 - val_acc: 0.9629\n",
      "Epoch 19/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.5170 - acc: 0.9638 - val_loss: 0.5114 - val_acc: 0.9629\n",
      "Epoch 20/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.5061 - acc: 0.9638 - val_loss: 0.5005 - val_acc: 0.9629\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 2.0e-06\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  17\n",
      "Dropout layer 2:  0.15161096104380103\n",
      "# nodes layer 4:  12\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 30us/sample - loss: 0.6643 - acc: 0.7750 - val_loss: 0.6598 - val_acc: 0.8979\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6542 - acc: 0.8315 - val_loss: 0.6500 - val_acc: 0.9344\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6442 - acc: 0.8681 - val_loss: 0.6400 - val_acc: 0.9585\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6337 - acc: 0.9024 - val_loss: 0.6297 - val_acc: 0.9630\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6229 - acc: 0.9200 - val_loss: 0.6189 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6117 - acc: 0.9335 - val_loss: 0.6078 - val_acc: 0.9629\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6000 - acc: 0.9460 - val_loss: 0.5964 - val_acc: 0.9629\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.5884 - acc: 0.9556 - val_loss: 0.5847 - val_acc: 0.9629\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.5765 - acc: 0.9594 - val_loss: 0.5727 - val_acc: 0.9629\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 1.9e-06\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.0\n",
      "# nodes layer 4:  12\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.5648 - acc: 0.9634 - val_loss: 0.5580 - val_acc: 0.9627\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.5519 - acc: 0.9637 - val_loss: 0.5450 - val_acc: 0.9628\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.5389 - acc: 0.9638 - val_loss: 0.5319 - val_acc: 0.9629\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.5257 - acc: 0.9638 - val_loss: 0.5187 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.5124 - acc: 0.9638 - val_loss: 0.5054 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4990 - acc: 0.9638 - val_loss: 0.4920 - val_acc: 0.9629\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.4857 - acc: 0.9638 - val_loss: 0.4788 - val_acc: 0.9629\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.4725 - acc: 0.9638 - val_loss: 0.4656 - val_acc: 0.9629\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 1.9e-06\n",
      "# nodes layer 1 :  22\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.05127330190640753\n",
      "# nodes layer 4:  12\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 31us/sample - loss: 0.6801 - acc: 0.5595 - val_loss: 0.6665 - val_acc: 0.6244\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6648 - acc: 0.6288 - val_loss: 0.6512 - val_acc: 0.7015\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6494 - acc: 0.6931 - val_loss: 0.6361 - val_acc: 0.7605\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.6346 - acc: 0.7526 - val_loss: 0.6214 - val_acc: 0.8145\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6201 - acc: 0.8050 - val_loss: 0.6069 - val_acc: 0.8538\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6058 - acc: 0.8455 - val_loss: 0.5928 - val_acc: 0.8796\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.5915 - acc: 0.8753 - val_loss: 0.5789 - val_acc: 0.9046\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.5778 - acc: 0.9022 - val_loss: 0.5652 - val_acc: 0.9275\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5643 - acc: 0.9242 - val_loss: 0.5518 - val_acc: 0.9466\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5509 - acc: 0.9425 - val_loss: 0.5386 - val_acc: 0.9565\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5377 - acc: 0.9529 - val_loss: 0.5256 - val_acc: 0.9612\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.5247 - acc: 0.9592 - val_loss: 0.5128 - val_acc: 0.9626\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5122 - acc: 0.9618 - val_loss: 0.5002 - val_acc: 0.9629\n",
      "Epoch 14/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.4995 - acc: 0.9628 - val_loss: 0.4878 - val_acc: 0.9629\n",
      "Epoch 15/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.4870 - acc: 0.9633 - val_loss: 0.4755 - val_acc: 0.9629\n",
      "Epoch 16/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4749 - acc: 0.9636 - val_loss: 0.4634 - val_acc: 0.9629\n",
      "Epoch 17/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.4624 - acc: 0.9637 - val_loss: 0.4513 - val_acc: 0.9629\n",
      "Epoch 18/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.4503 - acc: 0.9638 - val_loss: 0.4393 - val_acc: 0.9629\n",
      "Epoch 00018: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 1.0e-06\n",
      "# nodes layer 1 :  18\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.0\n",
      "# nodes layer 4:  7\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7134 - acc: 0.3293 - val_loss: 0.7104 - val_acc: 0.3464\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.7084 - acc: 0.3630 - val_loss: 0.7055 - val_acc: 0.3834\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.7036 - acc: 0.4034 - val_loss: 0.7007 - val_acc: 0.4266\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6988 - acc: 0.4461 - val_loss: 0.6959 - val_acc: 0.4672\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6940 - acc: 0.4833 - val_loss: 0.6912 - val_acc: 0.5053\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6893 - acc: 0.5251 - val_loss: 0.6865 - val_acc: 0.5500\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6846 - acc: 0.5649 - val_loss: 0.6818 - val_acc: 0.5838\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6799 - acc: 0.5933 - val_loss: 0.6771 - val_acc: 0.6107\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6753 - acc: 0.6191 - val_loss: 0.6724 - val_acc: 0.6372\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6706 - acc: 0.6451 - val_loss: 0.6677 - val_acc: 0.6638\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6659 - acc: 0.6734 - val_loss: 0.6630 - val_acc: 0.6924\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6612 - acc: 0.7047 - val_loss: 0.6583 - val_acc: 0.7238\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6565 - acc: 0.7385 - val_loss: 0.6536 - val_acc: 0.7545\n",
      "Epoch 14/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6518 - acc: 0.7661 - val_loss: 0.6490 - val_acc: 0.7800\n",
      "Epoch 15/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.6471 - acc: 0.7895 - val_loss: 0.6443 - val_acc: 0.8028\n",
      "Epoch 16/20\n",
      "82736/82736 [==============================] - 2s 21us/sample - loss: 0.6425 - acc: 0.8098 - val_loss: 0.6396 - val_acc: 0.8229\n",
      "Epoch 17/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.6378 - acc: 0.8262 - val_loss: 0.6349 - val_acc: 0.8331\n",
      "Epoch 18/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.6331 - acc: 0.8372 - val_loss: 0.6302 - val_acc: 0.8425\n",
      "Epoch 19/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6284 - acc: 0.8463 - val_loss: 0.6255 - val_acc: 0.8528\n",
      "Epoch 20/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6236 - acc: 0.8561 - val_loss: 0.6207 - val_acc: 0.8636\n",
      "\n",
      "Accuracy: 86.36%\n",
      "\n",
      "learning rate: 1.0e-06\n",
      "# nodes layer 1 :  18\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.12348325260288864\n",
      "# nodes layer 4:  4\n",
      "weight:  10.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 31us/sample - loss: 0.6723 - acc: 0.9638 - val_loss: 0.6744 - val_acc: 0.9629\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6716 - acc: 0.9637 - val_loss: 0.6733 - val_acc: 0.9629\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6702 - acc: 0.9638 - val_loss: 0.6719 - val_acc: 0.9629\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6686 - acc: 0.9638 - val_loss: 0.6704 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6671 - acc: 0.9638 - val_loss: 0.6691 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6662 - acc: 0.9638 - val_loss: 0.6676 - val_acc: 0.9629\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 9.4e-06\n",
      "# nodes layer 1 :  19\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.2\n",
      "# nodes layer 4:  4\n",
      "weight:  5.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 29us/sample - loss: 0.6627 - acc: 0.9511 - val_loss: 0.6526 - val_acc: 0.9628\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6418 - acc: 0.9618 - val_loss: 0.6299 - val_acc: 0.9629\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6188 - acc: 0.9635 - val_loss: 0.6060 - val_acc: 0.9629\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5946 - acc: 0.9638 - val_loss: 0.5813 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.5696 - acc: 0.9638 - val_loss: 0.5557 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.5433 - acc: 0.9638 - val_loss: 0.5311 - val_acc: 0.9629\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.5200 - acc: 0.9638 - val_loss: 0.5081 - val_acc: 0.9629\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 1.0e-02\n",
      "# nodes layer 1 :  21\n",
      "# nodes layer 2:  12\n",
      "Dropout layer 2:  0.0\n",
      "# nodes layer 4:  12\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.1388 - acc: 0.9613 - val_loss: 0.1345 - val_acc: 0.9629\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.1223 - acc: 0.9638 - val_loss: 0.1286 - val_acc: 0.9629\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.1218 - acc: 0.9638 - val_loss: 0.1274 - val_acc: 0.9629\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.1212 - acc: 0.9638 - val_loss: 0.1261 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.1208 - acc: 0.9638 - val_loss: 0.1259 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.1204 - acc: 0.9638 - val_loss: 0.1252 - val_acc: 0.9629\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 1.0e-06\n",
      "# nodes layer 1 :  18\n",
      "# nodes layer 2:  17\n",
      "Dropout layer 2:  0.060887202814234\n",
      "# nodes layer 4:  4\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 29us/sample - loss: 0.6588 - acc: 0.9561 - val_loss: 0.6602 - val_acc: 0.9585\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6558 - acc: 0.9588 - val_loss: 0.6570 - val_acc: 0.9610\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.6525 - acc: 0.9617 - val_loss: 0.6536 - val_acc: 0.9621\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6490 - acc: 0.9631 - val_loss: 0.6501 - val_acc: 0.9628\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.6455 - acc: 0.9636 - val_loss: 0.6465 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.6417 - acc: 0.9638 - val_loss: 0.6427 - val_acc: 0.9629\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.6381 - acc: 0.9638 - val_loss: 0.6388 - val_acc: 0.9629\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6341 - acc: 0.9638 - val_loss: 0.6348 - val_acc: 0.9629\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6300 - acc: 0.9638 - val_loss: 0.6306 - val_acc: 0.9629\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6259 - acc: 0.9638 - val_loss: 0.6264 - val_acc: 0.9629\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n",
      "learning rate: 1.4e-06\n",
      "# nodes layer 1 :  21\n",
      "# nodes layer 2:  20\n",
      "Dropout layer 2:  0.1295768650002961\n",
      "# nodes layer 4:  10\n",
      "weight:  10.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 2s 30us/sample - loss: 0.7296 - acc: 0.0570 - val_loss: 0.7250 - val_acc: 0.0447\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7272 - acc: 0.0645 - val_loss: 0.7228 - val_acc: 0.0516\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7246 - acc: 0.0739 - val_loss: 0.7206 - val_acc: 0.0628\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7226 - acc: 0.0832 - val_loss: 0.7183 - val_acc: 0.0734\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7202 - acc: 0.0930 - val_loss: 0.7167 - val_acc: 0.0846\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7179 - acc: 0.1063 - val_loss: 0.7147 - val_acc: 0.0932\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7161 - acc: 0.1213 - val_loss: 0.7127 - val_acc: 0.1052\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7141 - acc: 0.1379 - val_loss: 0.7107 - val_acc: 0.1237\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7122 - acc: 0.1566 - val_loss: 0.7093 - val_acc: 0.1476\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7103 - acc: 0.1770 - val_loss: 0.7075 - val_acc: 0.1703\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7085 - acc: 0.2000 - val_loss: 0.7056 - val_acc: 0.1959\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7068 - acc: 0.2234 - val_loss: 0.7040 - val_acc: 0.2260\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7051 - acc: 0.2513 - val_loss: 0.7026 - val_acc: 0.2536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7037 - acc: 0.2787 - val_loss: 0.7010 - val_acc: 0.2768\n",
      "Epoch 15/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7019 - acc: 0.3041 - val_loss: 0.6996 - val_acc: 0.3040\n",
      "Epoch 16/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7003 - acc: 0.3330 - val_loss: 0.6982 - val_acc: 0.3354\n",
      "Epoch 17/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6989 - acc: 0.3603 - val_loss: 0.6966 - val_acc: 0.3728\n",
      "Epoch 18/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6973 - acc: 0.3910 - val_loss: 0.6953 - val_acc: 0.4138\n",
      "Epoch 19/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6961 - acc: 0.4203 - val_loss: 0.6940 - val_acc: 0.4602\n",
      "Epoch 20/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.6947 - acc: 0.4578 - val_loss: 0.6927 - val_acc: 0.5018\n",
      "\n",
      "Accuracy: 50.18%\n",
      "\n",
      "learning rate: 1.0e-06\n",
      "# nodes layer 1 :  20\n",
      "# nodes layer 2:  14\n",
      "Dropout layer 2:  0.09956655061131581\n",
      "# nodes layer 4:  5\n",
      "weight:  15.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 31us/sample - loss: 0.7192 - acc: 0.0995 - val_loss: 0.7169 - val_acc: 0.0951\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7184 - acc: 0.1044 - val_loss: 0.7157 - val_acc: 0.0974\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 23us/sample - loss: 0.7172 - acc: 0.1067 - val_loss: 0.7151 - val_acc: 0.0998\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 22us/sample - loss: 0.7159 - acc: 0.1109 - val_loss: 0.7138 - val_acc: 0.1014\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.7153 - acc: 0.1142 - val_loss: 0.7131 - val_acc: 0.1043\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.7139 - acc: 0.1200 - val_loss: 0.7121 - val_acc: 0.1077\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.7132 - acc: 0.1232 - val_loss: 0.7110 - val_acc: 0.1118\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7120 - acc: 0.1292 - val_loss: 0.7104 - val_acc: 0.1173\n",
      "Epoch 9/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7114 - acc: 0.1360 - val_loss: 0.7093 - val_acc: 0.1254\n",
      "Epoch 10/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.7107 - acc: 0.1434 - val_loss: 0.7085 - val_acc: 0.1353\n",
      "Epoch 11/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7095 - acc: 0.1567 - val_loss: 0.7079 - val_acc: 0.1529\n",
      "Epoch 12/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7085 - acc: 0.1712 - val_loss: 0.7073 - val_acc: 0.1793\n",
      "Epoch 13/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7080 - acc: 0.1923 - val_loss: 0.7061 - val_acc: 0.2066\n",
      "Epoch 14/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7071 - acc: 0.2120 - val_loss: 0.7053 - val_acc: 0.2294\n",
      "Epoch 15/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7064 - acc: 0.2315 - val_loss: 0.7046 - val_acc: 0.2466\n",
      "Epoch 16/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7055 - acc: 0.2481 - val_loss: 0.7038 - val_acc: 0.2657\n",
      "Epoch 17/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7047 - acc: 0.2646 - val_loss: 0.7034 - val_acc: 0.2791\n",
      "Epoch 18/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7042 - acc: 0.2805 - val_loss: 0.7029 - val_acc: 0.2904\n",
      "Epoch 19/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.7035 - acc: 0.2885 - val_loss: 0.7023 - val_acc: 0.3015\n",
      "Epoch 20/20\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 0.7030 - acc: 0.3036 - val_loss: 0.7014 - val_acc: 0.3128\n",
      "\n",
      "Accuracy: 31.28%\n",
      "\n",
      "learning rate: 1.8e-05\n",
      "# nodes layer 1 :  20\n",
      "# nodes layer 2:  13\n",
      "Dropout layer 2:  0.06594191702403875\n",
      "# nodes layer 4:  7\n",
      "weight:  1.0\n",
      "\n",
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/20\n",
      "82736/82736 [==============================] - 3s 30us/sample - loss: 0.6940 - acc: 0.4850 - val_loss: 0.6609 - val_acc: 0.7887\n",
      "Epoch 2/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.6285 - acc: 0.8626 - val_loss: 0.5894 - val_acc: 0.9503\n",
      "Epoch 3/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.5537 - acc: 0.9533 - val_loss: 0.5093 - val_acc: 0.9629\n",
      "Epoch 4/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.4700 - acc: 0.9634 - val_loss: 0.4227 - val_acc: 0.9629\n",
      "Epoch 5/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.3873 - acc: 0.9637 - val_loss: 0.3454 - val_acc: 0.9629\n",
      "Epoch 6/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.3188 - acc: 0.9638 - val_loss: 0.2843 - val_acc: 0.9629\n",
      "Epoch 7/20\n",
      "82736/82736 [==============================] - 2s 27us/sample - loss: 0.2649 - acc: 0.9638 - val_loss: 0.2381 - val_acc: 0.9629\n",
      "Epoch 8/20\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.2255 - acc: 0.9638 - val_loss: 0.2056 - val_acc: 0.9629\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Accuracy: 96.29%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=30,\n",
    "                            x0=default_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of convergence shows the performance of each network, identified by its hyperparameters, on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20d8ca38358>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy found in HPT process -0.9628716707229614\n",
      "Best set of hyperparameters found in HPT process [2.7437177401845647e-06, 22, 14, 7, 0.06473657619308183, 10.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best validation accuracy found in HPT process {}\".format(search_result.fun))\n",
    "print(\"Best set of hyperparameters found in HPT process {}\".format(search_result.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0: 1.,\n",
    "           1:25.0}\n",
    "# uncomment only when to run a new model to delete the previous model\n",
    "del model\n",
    "K.clear_session()\n",
    "model = create_model(2.7437177401845647e-06, 20, 10, 4, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                520       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 44        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 779\n",
      "Trainable params: 779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82736 samples, validate on 20685 samples\n",
      "Epoch 1/40\n",
      "82736/82736 [==============================] - 2s 28us/sample - loss: 1.2801 - acc: 0.9589 - val_loss: 1.2587 - val_acc: 0.9517\n",
      "Epoch 2/40\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 1.0931 - acc: 0.9423 - val_loss: 1.1107 - val_acc: 0.9261\n",
      "Epoch 3/40\n",
      "82736/82736 [==============================] - 2s 24us/sample - loss: 0.9454 - acc: 0.9062 - val_loss: 0.9770 - val_acc: 0.8800\n",
      "Epoch 4/40\n",
      "82736/82736 [==============================] - 2s 26us/sample - loss: 0.8483 - acc: 0.8522 - val_loss: 0.8882 - val_acc: 0.8221\n",
      "Epoch 5/40\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.7911 - acc: 0.7977 - val_loss: 0.8392 - val_acc: 0.7750\n",
      "Epoch 6/40\n",
      "82736/82736 [==============================] - 2s 25us/sample - loss: 0.7552 - acc: 0.7560 - val_loss: 0.8100 - val_acc: 0.7397\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_acc', mode='auto', verbose=1, patience=5)\n",
    "history = model.fit(x=X_train,\n",
    "                        y=y_train,\n",
    "                        epochs=40,\n",
    "                        class_weight=weights,\n",
    "                        validation_split=0.2,\n",
    "                        batch_size=128,\n",
    "                        callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25856/25856 [==============================] - 0s 12us/sample - loss: 0.5167 - acc: 0.7407\n",
      "25856/25856 [==============================] - 0s 5us/sample\n",
      "[[18723  6170]\n",
      " [  534   429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.75      0.85     24893\n",
      "           1       0.07      0.45      0.11       963\n",
      "\n",
      "    accuracy                           0.74     25856\n",
      "   macro avg       0.52      0.60      0.48     25856\n",
      "weighted avg       0.94      0.74      0.82     25856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,batch_size=128, verbose=1)\n",
    "y_pred = model.predict(X_test, batch_size=128, verbose=1)\n",
    "y_pred_bool = np.round(y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_bool)\n",
    "#print(conf_matrix)\n",
    "print(conf_matrix)                             \n",
    "print(classification_report(y_test, y_pred_bool))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to show the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1#print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(conf_matrix, classes = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "y_pred_ = model.predict(X_test).ravel()\n",
    "fpr_, tpr_, thresholds_ = roc_curve(y_test, y_pred_)\n",
    "auc_ = auc(fpr_, tpr_)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_, tpr_, label='DNN Model (area = {:.3f})'.format(auc_))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
